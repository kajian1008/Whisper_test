{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOBR0pMFeja99NOmwB6MNMe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kajian1008/Whisper_test/blob/main/Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q03YwtkJS7Mc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchaudio\n",
        "\n",
        "SAMPLING_RATE = 16000\n",
        "\n",
        "import torch\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "from IPython.display import Audio\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "qoXUb4-iTL1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_ONNX = False # change this to True if you want to test onnx model\n",
        "if USE_ONNX:\n",
        "    !pip install -q onnxruntime\n",
        "\n",
        "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
        "                              model='silero_vad',\n",
        "                              force_reload=True,\n",
        "                              onnx=USE_ONNX)\n",
        "\n",
        "(get_speech_timestamps,\n",
        " save_audio,\n",
        " read_audio,\n",
        " VADIterator,\n",
        " collect_chunks) = utils"
      ],
      "metadata": {
        "id": "Jp6siC1zTVQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "directory = '/content/drive/MyDrive/ja_voice_finetuning/clips'\n",
        "out_directory = '/content/drive/MyDrive/ja_voice_finetuning/silero-clips'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(out_directory, exist_ok=True)\n",
        "\n",
        "# 指定されたディレクトリ内の全てのファイルをループ処理\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".mp3\"):  # ファイルが.mp3で終わる場合\n",
        "        file_path = os.path.join(directory, filename)  # ファイルのフルパスを取得\n",
        "        print(f'Processing file: {file_path}')\n",
        "\n",
        "        # read_audio とは、ファイルを読み込んで適切な形式（例: numpy array）に変換する関数です\n",
        "        audio = read_audio(file_path, sampling_rate=SAMPLING_RATE)\n",
        "\n",
        "        # get_speech_timestamps は、音声のタイムスタンプを検出する関数です\n",
        "        speech_timestamps = get_speech_timestamps(audio, model, sampling_rate=SAMPLING_RATE)\n",
        "\n",
        "        if speech_timestamps:  # タイムスタンプリストが空でない場合\n",
        "            # 処理された音声を保存する関数を呼び出す\n",
        "            output_path = os.path.join(out_directory, filename)\n",
        "            save_audio(output_path, collect_chunks(speech_timestamps, audio), sampling_rate=SAMPLING_RATE)\n",
        "        else:\n",
        "            print(f\"No speech detected in file: {file_path}\")"
      ],
      "metadata": {
        "id": "pR0IzH-uTamt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub openai-whisper\n",
        "!pip install kora"
      ],
      "metadata": {
        "id": "IvqkIXLZTk1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kora.xattr import get_id\n",
        "def get_gdrive_link(file_path):\n",
        "  fid = get_id(file_path)\n",
        "  print(f\"https://drive.google.com/file/d/{format(fid)}/view\")\n",
        "  return f\"https://drive.google.com/file/d/{format(fid)}/view\""
      ],
      "metadata": {
        "id": "XOyYOBfQVUUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import torch\n",
        "import os\n",
        "import csv  # CSVファイル出力のために必要\n",
        "\n",
        "# 現在利用可能なデバイスを確認\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Whisperモデルをロード\n",
        "model = whisper.load_model(\"turbo\", device=device)\n",
        "\n",
        "# 出力先のCSVファイルパスを定義\n",
        "output_csv_file = '/content/drive/MyDrive/ja_voice_finetuning/train0.csv'\n",
        "\n",
        "\n",
        "# CSVファイルを開き、結果を書き込む\n",
        "with open(output_csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    # CSVのヘッダーを書き込む\n",
        "    writer.writerow(['url', 'path','sampling_rate', 'correct', 'whisper'])\n",
        "\n",
        "    # 指定されたディレクトリ内の全てのファイルをループ処理\n",
        "    for filename in os.listdir(out_directory):\n",
        "        if filename.endswith(\".mp3\"):  # ファイルが.mp3で終わる場合\n",
        "            file_path = os.path.join(out_directory, filename)  # ファイルのフルパスを取得\n",
        "            print(f'Processing file: {file_path}')\n",
        "            result = model.transcribe(file_path, language=\"ja\")\n",
        "            # 結果をCSVに書き込む（ここではurlとcontentは空とする）\n",
        "            # https://drive.google.com/file/d/1ISt6Pg2eJFuHvV1Fkm2NZBvzAJ4grewq/view?usp=drive_link\n",
        "            writer.writerow([get_gdrive_link(file_path), file_path, SAMPLING_RATE ,'', result[\"text\"]])\n",
        "            print(result[\"text\"])\n",
        "\n",
        "print(f\"Processing complete. Results saved to {output_csv_file}\")"
      ],
      "metadata": {
        "id": "GD6rYkM2Vb8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}